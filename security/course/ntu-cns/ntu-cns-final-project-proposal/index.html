<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  NTU CNS Final Project Proposal
  #


  tags: NTUCNS
  #


  Problem description / Research question(秉學)
  #


  Terminology
  #

Federated Learning is a decentralized machine learning method that enables training models without exposing data. Traditional machine learning methods require all data to be centralized in one location for training, but Federated Learning enables models to be trained on many distributed devices, such as smartphones, tablets, or embedded devices, with each device training its own local data. This greatly reduces data transmission and storage requirements and better protects user privacy."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://bernie6401.github.io/security/course/ntu-cns/ntu-cns-final-project-proposal/"><meta property="og:site_name" content="SBK Hugo Site"><meta property="og:title" content="NTU CNS Final Project Proposal"><meta property="og:description" content="NTU CNS Final Project Proposal # tags: NTUCNS # Problem description / Research question(秉學) # Terminology # Federated Learning is a decentralized machine learning method that enables training models without exposing data. Traditional machine learning methods require all data to be centralized in one location for training, but Federated Learning enables models to be trained on many distributed devices, such as smartphones, tablets, or embedded devices, with each device training its own local data. This greatly reduces data transmission and storage requirements and better protects user privacy."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="security"><meta property="article:tag" content="NTUCNS"><meta property="article:tag" content="NTU"><title>NTU CNS Final Project Proposal | SBK Hugo Site</title>
<link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://bernie6401.github.io/security/course/ntu-cns/ntu-cns-final-project-proposal/><link rel=stylesheet href=/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.acdc41c8d39e6c69d70d8a23779875e0a3733fefead3e428d5344966bb12f562.js integrity="sha256-rNxByNOebGnXDYojd5h14KNzP+/q0+Qo1TRJZrsS9WI=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>SBK Hugo Site</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>NTU CNS Final Project Proposal</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li></li></ul></li><li><a href=#problem-description--research-question秉學>Problem description / Research question(秉學)</a><ul><li><a href=#terminology>Terminology</a></li><li><a href=#research-problem>Research Problem</a></li></ul></li><li><a href=#related-work-馮楷>Related work (馮楷)</a></li><li><a href=#plan-智翔>Plan (智翔)</a></li><li><a href=#timeline-馮楷>Timeline (馮楷)</a></li><li><a href=#deliverables歐華>Deliverables（歐華）</a></li><li><a href=#reference>Reference</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=ntu-cns-final-project-proposal>NTU CNS Final Project Proposal
<a class=anchor href=#ntu-cns-final-project-proposal>#</a></h1><h6 id=tags-ntucns>tags: <code>NTUCNS</code>
<a class=anchor href=#tags-ntucns>#</a></h6><h2 id=problem-description--research-question秉學>Problem description / Research question(秉學)
<a class=anchor href=#problem-description--research-question%e7%a7%89%e5%ad%b8>#</a></h2><h3 id=terminology>Terminology
<a class=anchor href=#terminology>#</a></h3><p>Federated Learning is a decentralized machine learning method that enables training models without exposing data. Traditional machine learning methods require all data to be centralized in one location for training, but Federated Learning enables models to be trained on many distributed devices, such as smartphones, tablets, or embedded devices, with each device training its own local data. This greatly reduces data transmission and storage requirements and better protects user privacy.</p><hr><p>Privacy Preserving is a method of designing and implementing computing systems aimed at protecting the privacy of data and personal information. It is typically a technique used in the exchange or processing of data to ensure the confidentiality, integrity, and availability of data.
Privacy preserving techniques can help ensure that data is protected and that sensitive information is not disclosed even during data sharing, analysis, or storage. For example, techniques such as data encryption, differential privacy, and multi-party computation can be used to protect data privacy, and these techniques have wide applications in data analysis and machine learning.</p><h3 id=research-problem>Research Problem
<a class=anchor href=#research-problem>#</a></h3><p>In this paper, they proposed a method to prevent a malicious server as an attacker as their threat model. However, each client in the same group shared the same public/private key so that the attacker can pretend a benign user and exploit part of the packages.
So, our threat model is if the attacker is one of the user in a group, he can decrypt a part of the packages transferred in this group and the confidentiality property is gone.</p><h2 id=related-work-馮楷>Related work (馮楷)
<a class=anchor href=#related-work-%e9%a6%ae%e6%a5%b7>#</a></h2><ul><li><p>FedML-HE:</p><ul><li>Limitations:</li></ul></li><li><p>Decentralized Threshold HE:
The authors provided a $(t,n)$-theshold HE scheme based on CKKS HE scheme, where a center server is no longer needed for decryption. Instead, the decryption process can be done, when $t$ out of $n$ parties agree to decrypt.</p><ul><li>Limitations:
To ensure the joint key security, smudging errors are required which inevitably enlarge the entire parameter size, resulting in a huge computational overhead.</li></ul></li><li><p>Proxy Re-Encryption:
The scheme can re-encrypt ciphertext for multiple receivers at a time by generating the re-encryption key from private and other users&rsquo; public identities, which meets the requirement of FL.</p><ul><li>Limitations:
This scheme relies on a trusted authority KGC(key generation center) for initialization. Moreover, it assumes that all participants in the federated learning system are honest and follow the protocol correctly.</li></ul></li></ul><h2 id=plan-智翔>Plan (智翔)
<a class=anchor href=#plan-%e6%99%ba%e7%bf%94>#</a></h2><p>Our method would be mainly based on the general scheme proposed for the practical deployment of homomorphic-encryption-based federated learning [2]. Several security issues remain unsolved since the scheme aims to keep generality. We will apply two or more possible schemes to the general scheme to improve data security.</p><ul><li><p>Key management
In the general scheme, there exists only one pair of public/private keys. Once a client is compromised or is malicious, they can easily decrypt the gradient from another client and possibly reverse the gradient to the original data using the gradient inversion attack. To defend against this type of attack, we may not allow clients to share the same pair of public/private keys.
On the other hand, the key pair is published by a server. If the server is compromised or malicious, then gradients from clients can be decrypted. By the gradient inversion attack, local data can be reversed. Thus decentralization is important to any federated learning scheme.
The following are two latest solutions to the problems.</p><ul><li>Proxy re-encryption [4]
This method establishes a key management held by a trusted third party and allows all clients to use distinct key pairs. The first problem is solved, while decentralization is not fulfilled.</li><li>Threshold homomorphic encryption [3]
This method establishes a decentralized scheme by using threshold cryptography. At the same time, a single client can not decrypt any gradient from another, which solves the first problem.</li></ul></li><li><p>Poisoning attack
Poisoning attack is still one severe threat to federated learning. A malicious or compromised client can upload a bad gradient to the server and reduce the accuracy of the training model [5]. We will discuss this attack and try to find a scheme to mitigate poisoning attacks.</p></li><li><p>Comparison
We will compare the security and efficiency of each scheme. For the security part, we will introduce several threats and evaluate the security level of a scheme by checking if the scheme can defend against these threats.</p></li></ul><h2 id=timeline-馮楷>Timeline (馮楷)
<a class=anchor href=#timeline-%e9%a6%ae%e6%a5%b7>#</a></h2><p>5/8: Finish studying paper
5/15: Apply Decentralized Threshold HE on the FedML system
5/22: Apply Proxy Re-Encryption on the FedML system
5/29: Finish the report
6/5, 6/12: Oral Presentation</p><h2 id=deliverables歐華>Deliverables（歐華）
<a class=anchor href=#deliverables%e6%ad%90%e8%8f%af>#</a></h2><p>The final deliverable of this project will be a comprehensive analysis of the security vulnerabilities in the FedML-HE system, as well as enhancements through the addition of threshold homomorphic encryption and proxy re-encryption. These enhancements will be presented in a detailed report, as well as their potential benefits and limitations in a practical scenario.</p><h2 id=reference>Reference
<a class=anchor href=#reference>#</a></h2><ul><li>Privacy Preserving using Homomorphic Encryption
<a href=https://eprint.iacr.org/2017/715.pdf>Privacy-Preserving Deep Learning via Additively Homomorphic Encryption</a>
<a href=https://paperswithcode.com/paper/fedml-he-an-efficient-homomorphic-encryption>FedML-HE: An Efficient Homomorphic-Encryption-Based Privacy-Preserving Federated Learning System</a>
<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9223642&amp;tag=1">How to Securely Collaborate on Data: Decentralized Threshold HE and Secure Key Update</a>
<a href=https://dl.acm.org/doi/pdf/10.1145/3540199>ID-Based Multireceiver Homomorphic Proxy Re-Encryption in Federated Learning</a>
<a href=https://arxiv.org/pdf/2301.05795.pdf>Poisoning Attacks and Defenses in Federated Learning: A Survey</a></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li></li></ul></li><li><a href=#problem-description--research-question秉學>Problem description / Research question(秉學)</a><ul><li><a href=#terminology>Terminology</a></li><li><a href=#research-problem>Research Problem</a></li></ul></li><li><a href=#related-work-馮楷>Related work (馮楷)</a></li><li><a href=#plan-智翔>Plan (智翔)</a></li><li><a href=#timeline-馮楷>Timeline (馮楷)</a></li><li><a href=#deliverables歐華>Deliverables（歐華）</a></li><li><a href=#reference>Reference</a></li></ul></nav></div></aside></main></body></html>