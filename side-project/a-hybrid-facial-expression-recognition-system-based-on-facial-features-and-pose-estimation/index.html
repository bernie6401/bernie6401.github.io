<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  A Hybrid Facial Expression Recognition System Based on Facial Features and Pose Estimation
  #


  tags: NTUST Emotional Recognition Openpose PyTorch Special Topic
  #

:::spoiler
[TOC]
:::

  Author
  #

JING-MING GUO1, (Senior Member, IEEE), CHIH-HSIEN HSIA2,  (Member, IEEE), PING-HSUEH HO1, (Bachelor), YANG-CHEN CHANG1, (Bachelor)
1Department of Electrical Engineering, National Taiwan University of Science and Technology
Taipei City 106, Taipei County, Taiwan
2Department of Computer Science and Information Engineering, National Ilan University, Yilan City 260, Yilan County, Taiwan"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://bernie6401.github.io/side-project/a-hybrid-facial-expression-recognition-system-based-on-facial-features-and-pose-estimation/"><meta property="og:site_name" content="SBK Hugo Site"><meta property="og:title" content="A Hybrid Facial Expression Recognition System Based on Facial Features and Pose Estimation"><meta property="og:description" content="A Hybrid Facial Expression Recognition System Based on Facial Features and Pose Estimation # tags: NTUST Emotional Recognition Openpose PyTorch Special Topic # :::spoiler [TOC] :::
Author # JING-MING GUO1, (Senior Member, IEEE), CHIH-HSIEN HSIA2, (Member, IEEE), PING-HSUEH HO1, (Bachelor), YANG-CHEN CHANG1, (Bachelor)
1Department of Electrical Engineering, National Taiwan University of Science and Technology Taipei City 106, Taipei County, Taiwan 2Department of Computer Science and Information Engineering, National Ilan University, Yilan City 260, Yilan County, Taiwan"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="side-project"><meta property="article:tag" content="NTUST"><meta property="article:tag" content="Special Topic"><title>A Hybrid Facial Expression Recognition System Based on Facial Features and Pose Estimation | SBK Hugo Site</title>
<link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://bernie6401.github.io/side-project/a-hybrid-facial-expression-recognition-system-based-on-facial-features-and-pose-estimation/><link rel=stylesheet href=/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.acdc41c8d39e6c69d70d8a23779875e0a3733fefead3e428d5344966bb12f562.js integrity="sha256-rNxByNOebGnXDYojd5h14KNzP+/q0+Qo1TRJZrsS9WI=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>SBK Hugo Site</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>A Hybrid Facial Expression Recognition System Based on Facial Features and Pose Estimation</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li></li></ul></li><li><a href=#author>Author</a></li><li><a href=#data>Data</a></li><li><a href=#models>Models</a></li><li><a href=#run>Run</a></li><li><a href=#result>Result</a><ul><li><a href=#7-classes---face--body--whole>7 Classes - Face / Body / Whole</a></li><li><a href=#12-classes---face--body--whole>12 Classes - Face / Body / Whole</a></li></ul></li><li><a href=#more-detail>More Detail</a></li><li><a href=#update>Update</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=a-hybrid-facial-expression-recognition-system-based-on-facial-features-and-pose-estimation>A Hybrid Facial Expression Recognition System Based on Facial Features and Pose Estimation
<a class=anchor href=#a-hybrid-facial-expression-recognition-system-based-on-facial-features-and-pose-estimation>#</a></h1><h6 id=tags-ntust-emotional-recognition-openpose-pytorch-special-topic>tags: <code>NTUST</code> <code>Emotional Recognition</code> <code>Openpose</code> <code>PyTorch</code> <code>Special Topic</code>
<a class=anchor href=#tags-ntust-emotional-recognition-openpose-pytorch-special-topic>#</a></h6><p>:::spoiler
[TOC]
:::</p><h2 id=author>Author
<a class=anchor href=#author>#</a></h2><p>JING-MING GUO<sup>1</sup>, (Senior Member, IEEE), CHIH-HSIEN HSIA<sup>2</sup>, (Member, IEEE), PING-HSUEH HO<sup>1</sup>, (Bachelor), YANG-CHEN CHANG<sup>1</sup>, (Bachelor)</p><p><sup>1</sup>Department of Electrical Engineering, National Taiwan University of Science and Technology
Taipei City 106, Taipei County, Taiwan
<sup>2</sup>Department of Computer Science and Information Engineering, National Ilan University, Yilan City 260, Yilan County, Taiwan</p><p><sup>1</sup><a href=mailto:jmguo@mail.ntust.edu.tw>jmguo@mail.ntust.edu.tw</a>, <a href=mailto:bernie6401@gmail.com>bernie6401@gmail.com</a>, <a href=mailto:Max.chang965132@gmail.com>Max.chang965132@gmail.com</a>
<sup>2</sup><a href=mailto:chhsia625@gmail.com>chhsia625@gmail.com</a></p><h2 id=data>Data
<a class=anchor href=#data>#</a></h2><p>The datasets are placed in the datasets folder, we prepare them as the link you can download by correct structure, please see the <a href=datasets/README.txt>data readme</a>.</p><p>In the folder, we just use <a href=https://www.unige.ch/cisa/gemep>GEMEP dataset</a> that has whole body including face and body especially as our research data and compare with <a href=https://ieeexplore.ieee.org/abstract/document/8769871>other paper</a>.</p><h2 id=models>Models
<a class=anchor href=#models>#</a></h2><p>The modes&rsquo; weights are placed in the models folder, we prepare them as the link you can download by correct structure, please see <a href=models/README.txt>model readme</a>.</p><p>We use <a href=https://github.com/filby89/body-face-emotion-recognition>Fusing Body Posture model</a> as our body model and also use <a href=https://github.com/JiaweiShiCV/Amend-Representation-Module>ARM model</a> as our face model. We also use weights that ARM team(named epoch59_acc0.9205.pth in download link) and Fusing Body team provided as our pretrained weight respectively.</p><p>Our model structure is as below:</p><img src=./models/model_structure.png alt=IMG1 style=zoom:75%><h2 id=run>Run
<a class=anchor href=#run>#</a></h2><blockquote><p>Setup environment:</p></blockquote><pre tabindex=0><code>pip install -U scikit-learn
conda install -c conda-forge matplotlib
conda install -c conda-forge argparse
conda install -c conda-forge tqdm
conda install -c conda-forge wandb
conda install -c anaconda pillow
</code></pre><blockquote><p>Demo GEMEP with 7 classes</p></blockquote><pre tabindex=0><code>python test_leave_one_out.py -p --data_type GEMEP --num_classes 7
</code></pre><blockquote><p>Demo GEMEP with 12 classes</p></blockquote><pre tabindex=0><code>python test_leave_one_out.py -p --data_type GEMEP --num_classes 12
</code></pre><h2 id=result>Result
<a class=anchor href=#result>#</a></h2><h3 id=7-classes---face--body--whole>7 Classes - Face / Body / Whole
<a class=anchor href=#7-classes---face--body--whole>#</a></h3><img src=./Confusion_matrix/GEMEP_Face7_acc0.66.png>
<img src=./Confusion_matrix/GEMEP_Body7_acc0.5833.png>
<img src=./Confusion_matrix/GEMEP_Whole7_acc0.6734.png><h3 id=12-classes---face--body--whole>12 Classes - Face / Body / Whole
<a class=anchor href=#12-classes---face--body--whole>#</a></h3><img src=./Confusion_matrix/GEMEP_Face12_acc0.5083.png>
<img src=./Confusion_matrix/GEMEP_Body12_acc0.525.png>
<img src=./Confusion_matrix/GEMEP_Whole12_acc0.6083.png><h2 id=more-detail>More Detail
<a class=anchor href=#more-detail>#</a></h2><p>You can download <a href=./A_Hybrid_Facial_Expression_Recognition_System_Based_on_Facial_Features_and_Pose_Estimation.pdf>here</a> for more experience detail such as platform, software version, or hyper parameters, etc.</p><h2 id=update>Update
<a class=anchor href=#update>#</a></h2><ul><li>2022/08/14 update dataset_leave_one_out.py and test_leave_one_out.py files about adding emo_tranform() function in former file to parse num_classes argument and let the user used it more convenient. Now you can just use the comment above and no need to adjust any code in any file in testing mode.</li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li></li></ul></li><li><a href=#author>Author</a></li><li><a href=#data>Data</a></li><li><a href=#models>Models</a></li><li><a href=#run>Run</a></li><li><a href=#result>Result</a><ul><li><a href=#7-classes---face--body--whole>7 Classes - Face / Body / Whole</a></li><li><a href=#12-classes---face--body--whole>12 Classes - Face / Body / Whole</a></li></ul></li><li><a href=#more-detail>More Detail</a></li><li><a href=#update>Update</a></li></ul></nav></div></aside></main></body></html>