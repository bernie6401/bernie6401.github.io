<!doctype html><html lang=en-us dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=html><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.145.0"><meta name=generator content="Relearn 7.6.0+b932d301d7838f3c1a50e318e216b55ce5cc9148"><meta name=description content="Understanding Real-world Threats to Deep Learning Models in Android Apps tags: Meeting Paper NTU :::info Deng, Z., Chen, K., Meng, G., Zhang, X., Xu, K., & Cheng, Y. (2022, November). Understanding real-world threats to deep learning models in android apps. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (pp. 785-799). :::
Background :::spoiler What is Adversarial Example? - 運用對抗例攻擊深度學習模型
所謂對抗例，是一種刻意製造的、讓機器學習模型判斷錯誤的輸入資料。最早是 Szegedy et al（2013）發現對於用 ImageNet、AlexNet 等資料集訓練出來的影像辨識模型，常常只需要輸入端的微小的變動，就可以讓輸出結果有大幅度的改變。例如取一張卡車的照片，可以被模型正確辨識，但只要改變影像中的少數像素，就可以讓模型辨識錯誤，而且前後對影像的改變非常少，對肉眼而言根本分不出差異。 :::"><meta name=author content><meta name=twitter:card content="summary"><meta name=twitter:title content="Understanding Real-world Threats to Deep Learning Models in Android Apps :: SBK Hugo Site"><meta name=twitter:description content="Understanding Real-world Threats to Deep Learning Models in Android Apps tags: Meeting Paper NTU :::info Deng, Z., Chen, K., Meng, G., Zhang, X., Xu, K., & Cheng, Y. (2022, November). Understanding real-world threats to deep learning models in android apps. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (pp. 785-799). :::
Background :::spoiler What is Adversarial Example? - 運用對抗例攻擊深度學習模型
所謂對抗例，是一種刻意製造的、讓機器學習模型判斷錯誤的輸入資料。最早是 Szegedy et al（2013）發現對於用 ImageNet、AlexNet 等資料集訓練出來的影像辨識模型，常常只需要輸入端的微小的變動，就可以讓輸出結果有大幅度的改變。例如取一張卡車的照片，可以被模型正確辨識，但只要改變影像中的少數像素，就可以讓模型辨識錯誤，而且前後對影像的改變非常少，對肉眼而言根本分不出差異。 :::"><meta property="og:url" content="https://bernie6401.github.io/survey-papers/android-+-security/understanding-real-world-threats-to-deep-learning-models-in-android-apps/index.html"><meta property="og:site_name" content="SBK Hugo Site"><meta property="og:title" content="Understanding Real-world Threats to Deep Learning Models in Android Apps :: SBK Hugo Site"><meta property="og:description" content="Understanding Real-world Threats to Deep Learning Models in Android Apps tags: Meeting Paper NTU :::info Deng, Z., Chen, K., Meng, G., Zhang, X., Xu, K., & Cheng, Y. (2022, November). Understanding real-world threats to deep learning models in android apps. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (pp. 785-799). :::
Background :::spoiler What is Adversarial Example? - 運用對抗例攻擊深度學習模型
所謂對抗例，是一種刻意製造的、讓機器學習模型判斷錯誤的輸入資料。最早是 Szegedy et al（2013）發現對於用 ImageNet、AlexNet 等資料集訓練出來的影像辨識模型，常常只需要輸入端的微小的變動，就可以讓輸出結果有大幅度的改變。例如取一張卡車的照片，可以被模型正確辨識，但只要改變影像中的少數像素，就可以讓模型辨識錯誤，而且前後對影像的改變非常少，對肉眼而言根本分不出差異。 :::"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="Survey Papers"><meta property="article:tag" content="Meeting Paper"><meta property="article:tag" content="NTU"><meta itemprop=name content="Understanding Real-world Threats to Deep Learning Models in Android Apps :: SBK Hugo Site"><meta itemprop=description content="Understanding Real-world Threats to Deep Learning Models in Android Apps tags: Meeting Paper NTU :::info Deng, Z., Chen, K., Meng, G., Zhang, X., Xu, K., & Cheng, Y. (2022, November). Understanding real-world threats to deep learning models in android apps. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (pp. 785-799). :::
Background :::spoiler What is Adversarial Example? - 運用對抗例攻擊深度學習模型
所謂對抗例，是一種刻意製造的、讓機器學習模型判斷錯誤的輸入資料。最早是 Szegedy et al（2013）發現對於用 ImageNet、AlexNet 等資料集訓練出來的影像辨識模型，常常只需要輸入端的微小的變動，就可以讓輸出結果有大幅度的改變。例如取一張卡車的照片，可以被模型正確辨識，但只要改變影像中的少數像素，就可以讓模型辨識錯誤，而且前後對影像的改變非常少，對肉眼而言根本分不出差異。 :::"><meta itemprop=wordCount content="425"><meta itemprop=keywords content="Meeting Paper,NTU"><title>Understanding Real-world Threats to Deep Learning Models in Android Apps :: SBK Hugo Site</title>
<link href=/fonts/fontawesome/css/fontawesome-all.min.css?1743619851 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/fonts/fontawesome/css/fontawesome-all.min.css?1743619851 rel=stylesheet></noscript><link href=/css/perfect-scrollbar/perfect-scrollbar.min.css?1743619851 rel=stylesheet><link href=/css/theme.min.css?1743619851 rel=stylesheet><link href=/css/format-html.min.css?1743619851 rel=stylesheet id=R-format-style><link href=/css/auto-complete/auto-complete.min.css?1743619851 rel=stylesheet><script src=/js/auto-complete/auto-complete.min.js?1743619851 defer></script><script src=/js/lunr/lunr.min.js?1743619851 defer></script><script src=/js/lunr/lunr.stemmer.support.min.js?1743619851 defer></script><script src=/js/lunr/lunr.multi.min.js?1743619851 defer></script><script src=/js/lunr/lunr.en.min.js?1743619851 defer></script><script src=/js/search.min.js?1743619851 defer></script><script>window.relearn=window.relearn||{},window.relearn.min=`.min`,window.relearn.path="/survey-papers/android-&#43;-security/understanding-real-world-threats-to-deep-learning-models-in-android-apps/index.html",window.relearn.relBasePath="../../..",window.relearn.relBaseUri="../../..",window.relearn.absBaseUri="https://bernie6401.github.io",window.relearn.contentLangs=["en"],window.relearn.index_js_url="/searchindex.en.js?1743619851",window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.disableInlineCopyToClipboard=!1,window.relearn.enableBlockCodeWrap=!0,window.relearn.getItem=(e,t)=>e.getItem(t),window.relearn.setItem=(e,t,n)=>e.setItem(t,n),window.relearn.removeItem=(e,t)=>e.removeItem(t),window.relearn.themevariants=["auto"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&(document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}})),window.relearn.markVariant())},window.relearn.markVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant");document.querySelectorAll(".R-variantswitcher select").forEach(t=>{t.value=e})},window.relearn.initVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant(),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script></head><body class="mobile-support html" data-url=/survey-papers/android-&amp;#43;-security/understanding-real-world-threats-to-deep-learning-models-in-android-apps/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div><div class="topbar-button topbar-button-toc" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title="Table of Contents (CTRL+ALT+t)"><i class="fa-fw fas fa-list-alt"></i></button><div class=topbar-content><div class=topbar-content-wrapper><nav class=TableOfContents><ul><li><ul><li></li></ul></li><li><a href=#background>Background</a></li></ul></nav></div></div></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/index.html><span itemprop=name>SBK Hugo Site</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/survey-papers/index.html><span itemprop=name>Survey Papers</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Understanding Real-world Threats to Deep Learning Models in Android Apps</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-prev" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/survey-papers/android-+-security/uncovering-intent-based-leak-of-sensitive-data-in-android-framework/index.html title="Uncovering Intent based Leak of Sensitive Data in Android Framework (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a></div><div class="topbar-button topbar-button-next" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/survey-papers/android-+-security/vaptai_-a-threat-model-for-vulnerability-assessment-and-pentesting-of-android-and-ios-mobile-banking-apps/index.html title="VAPTAi: A Threat Model for Vulnerability Assessment and Pentesting of Android and iOS Mobile Banking Apps (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable survey-papers" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline><div class="R-taxonomy taxonomy-tags cstyle tags" title=Tags style=--VARIABLE-TAGS-BG-color:var(--INTERNAL-TAG-BG-color)><ul><li><a class=term-link href=/tags/meeting-paper/index.html>Meeting Paper</a></li><li><a class=term-link href=/tags/ntu/index.html>NTU</a></li></ul></div></header><h1 id=understanding-real-world-threats-to-deep-learning-models-in-android-apps>Understanding Real-world Threats to Deep Learning Models in Android Apps</h1><h1 id=understanding-real-world-threats-to-deep-learning-models-in-android-apps>Understanding Real-world Threats to Deep Learning Models in Android Apps</h1><h6 id=tags-meeting-paper-ntu>tags: <code>Meeting Paper</code> <code>NTU</code></h6><p>:::info
Deng, Z., Chen, K., Meng, G., Zhang, X., Xu, K., & Cheng, Y. (2022, November). Understanding real-world threats to deep learning models in android apps. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security (pp. 785-799).
:::</p><h2 id=background>Background</h2><p>:::spoiler <a href=https://medium.com/trustableai/%E9%87%9D%E5%B0%8D%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E7%9A%84%E6%83%A1%E6%84%8F%E8%B3%87%E6%96%99%E6%94%BB%E6%93%8A-%E4%B8%80-e94987742767 rel=external target=_blank>What is Adversarial Example? - 運用對抗例攻擊深度學習模型</a></p><blockquote><p>所謂對抗例，是一種刻意製造的、讓機器學習模型判斷錯誤的輸入資料。最早是 Szegedy et al（2013）發現對於用 ImageNet、AlexNet 等資料集訓練出來的影像辨識模型，常常只需要輸入端的微小的變動，就可以讓輸出結果有大幅度的改變。例如取一張卡車的照片，可以被模型正確辨識，但只要改變影像中的少數像素，就可以讓模型辨識錯誤，而且前後對影像的改變非常少，對肉眼而言根本分不出差異。
:::</p></blockquote><p>:::spoiler <a href=https://blog.csdn.net/chehec2010/article/details/91360772 rel=external target=_blank>hook（钩子函数）</a>
<a href=https://www.zixuerumen.com/17234.html rel=external target=_blank>钩子函数是什么意思</a></p><blockquote><p>在Windows系統中一切皆消息，按鍵盤上的鍵，也是一個消息。Hook 的意思是鉤住，也就是在消息過去之前，先把消息鉤住，不讓其傳遞，使用戶可以優先處理。執行這種操作的函數也稱為鉤子函數。</p></blockquote><p><a href=https://www.fineart-tech.com/index.php/ch/news/699-fineartsecurity-apihook rel=external target=_blank>Hook API讓應用程式乖乖轉彎，駭客也是這麼做 </a>:::</p><p>:::spoiler <a href=https://www.geeksforgeeks.org/remote-procedure-call-rpc-in-operating-system/ rel=external target=_blank>Remote Procedure Call (RPC) in Operating System</a></p><blockquote><p>Remote Procedure Call (RPC) is a powerful technique for constructing distributed, client-server based applications. It is based on extending the conventional local procedure calling so that the called procedure need not exist in the same address space as the calling procedure. The two processes may be on the same system, or they may be on different systems with a network connecting them.</p></blockquote><hr><p>在王凡老師的OS中也有提到RPC(Ch.3 P3.54)</p><blockquote><p>Remote procedure call abstract procedure calls between processes on networked systems</p></blockquote><p>簡單來說，他可以執行遠端PC的某一個module或method，而這東西的好處是可以降低programmer學習IPC的障礙，因為這種方式更直觀，大概就像下圖一樣
<a href=#R-image-eb83fcc8919efe3e5dddcf1ebc8ab299 class=lightbox-link><img class="lazy lightbox figure-image" loading=lazy src=https://media.geeksforgeeks.org/wp-content/uploads/operating-system-remote-procedure-call-1.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-eb83fcc8919efe3e5dddcf1ebc8ab299><img class="lazy lightbox lightbox-image" loading=lazy src=https://media.geeksforgeeks.org/wp-content/uploads/operating-system-remote-procedure-call-1.png></a>
:::</p><p>:::spoiler <a href=https://www.researchgate.net/figure/Example-Class-Hierarchy-Analysis-CHA-Our-Class-Hierarchy-Analysis-is-a-static-compile_fig1_269196977 rel=external target=_blank>What is Class Hierarchy Analysis?</a></p><blockquote><p>It is a static (compile time) analysis that uses the class hierarchy to compute which method implementations can be invoked by objects of each class type. The left diagram above shows an example hierarchy of five classes where subclasses point to their parent class: D and E are subclasses of C while B and C are subclasses of A.
<a href=#R-image-f9fd50a5ded9d5e98c2db4e77814c98e class=lightbox-link><img class="lazy lightbox figure-image" loading=lazy src=https://www.researchgate.net/profile/Zachary-Tatlock/publication/269196977/figure/fig1/AS:668907362856968@1536491351260/Example-Class-Hierarchy-Analysis-CHA-Our-Class-Hierarchy-Analysis-is-a-static-compile.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-f9fd50a5ded9d5e98c2db4e77814c98e><img class="lazy lightbox lightbox-image" loading=lazy src=https://www.researchgate.net/profile/Zachary-Tatlock/publication/269196977/figure/fig1/AS:668907362856968@1536491351260/Example-Class-Hierarchy-Analysis-CHA-Our-Class-Hierarchy-Analysis-is-a-static-compile.png></a>
:::</p></blockquote><p><a href=https://blog.csdn.net/zw0Pi8G5C1x/article/details/121571055 rel=external target=_blank>8 種主流深度學習框架介紹</a>
<a href=https://ithelp.ithome.com.tw/articles/10272501 rel=external target=_blank>[Day 21] 媽! Keras 和 TensorFlow 在亂存模型啦! ( TFLite 輕量模型)</a></p><p>:::spoiler <a href=https://d246810g2000.medium.com/%E6%96%87%E5%AD%97%E8%BE%A8%E8%AD%98%E6%96%B9%E6%B3%95%E7%B5%B1%E6%95%B4-1e3d3ba5fe54 rel=external target=_blank>What is OCR? - 文字辨識方法統整</a></p><blockquote><p>OCR 英文全稱是 Optical Character Recognition，中文叫做光學字元識別，目前是文字辨識的統稱，已不限於文檔或書本文字辨識，更包括辨識自然場景下的文字，又可以稱為 STR（Scene Text Recognition）。</p><p>圖1 中有三個大分類，包含 Text detection, Text recognition, Text spotting，Text detection 主要是偵測文字在影像中的哪個位置，Text recognition 主要是將偵測後的結果拿來辨識是什麼文字，而 Text spotting 則是將 detection 和 recognition 整合到一個 End-to-End 的網路中來進行文字辨識。
<a href=#R-image-26b00a19ce9e7766dd29476f6dc4a848 class=lightbox-link><img class="lazy lightbox figure-image" loading=lazy src=https://miro.medium.com/v2/resize:fit:720/format:webp/1*UxmtG_Y3E4NyZVeoGnD3OQ.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-26b00a19ce9e7766dd29476f6dc4a848><img class="lazy lightbox lightbox-image" loading=lazy src=https://miro.medium.com/v2/resize:fit:720/format:webp/1*UxmtG_Y3E4NyZVeoGnD3OQ.png></a>
:::</p></blockquote><p><a href=https://ithelp.ithome.com.tw/articles/10233788 rel=external target=_blank>互聯網行業中，常說的API和SDK是什麼？</a></p><p><a href=https://www.jianshu.com/p/4272e0805da3 rel=external target=_blank>What is Tiny Encryption Algorithm(TEA)?</a></p><p><a href=https://blog.csdn.net/tugouxp/article/details/123262864 rel=external target=_blank>What is MACE framework? - 小米AI推理框架MACE介绍</a></p><p>:::spoiler <a href=https://www.techtarget.com/searchitoperations/definition/trusted-execution-environment-TEE rel=external target=_blank>What is a trusted execution environment (TEE)?</a></p><blockquote><p>A trusted execution environment (TEE) is an area on the main processor of a device that is separated from the system&rsquo;s main operating system (OS). It ensures data is stored, processed and protected in a secure environment. TEEs provide protection for anything connected, such as a trusted application (TA), by enabling an isolated, cryptographic electronic structure and end-to-end security. This includes the execution of authenticated code, confidentiality, authenticity, privacy, system integrity and data access rights.
:::</p></blockquote><p>:::spoiler What is Perturbation Budget? - From ChatGPT</p><blockquote><p>在深度學習安全領域，擾動預算指的是可以引入到輸入數據中的最大擾動或失真程度，而不會顯著影響深度學習模型的輸出或預測結果。</p><p>擾動通常作為對抗攻擊的一部分引入，攻擊者試圖以某種方式操縱輸入數據，使模型出現誤分類或產生錯誤輸出。通過設置擾動預算，系統可以限制這些攻擊的影響，並提高其對抗攻擊的魯棒性。</p><p>擾動預算的定義方式因應用和攻擊類型而異。例如，它可以用擾動向量的L2或L∞範數來衡量，分別代表原始輸入數據和擾動後數據之間的歐幾里得距離或最大絕對差值。</p><p>總的來說，擾動預算是評估深度學習模型安全性和魯棒性的重要參數，特別是在安全性是重要關注點的應用中。
:::</p></blockquote><p>:::spoiler <a href=https://datasciocean.tech/machine-learning-basic-concept/machine-learning-model-inference/ rel=external target=_blank>What is quantization? - 使用機器學習解決問題的五步驟 : 模型推論</a></p><blockquote><p>Pruning 與 Quantization</p><p>我們在這裡簡單說明 Pruning 與 Quantization 的概念，如果想更深入學習模型效能、速度與能耗的最佳化問題，可以參考 TensorFlow 的官方文件。</p><p>Pruning : 全名為 Weight Pruning，中文稱為「權重修剪」。透過觀察模型中哪些參數對於模型的預測過程較沒有影響，將這些參數移除，達到降低模型複雜度與運算量的目的。
Quantization : 中文稱為「量化」。模型中的參數如果是 32-bit 的浮點數，將其轉為 8-bit。透過簡化模型中參數的「精確程度」達到降低模型體積並提高運算速度的目的。
不管是 Pruning 或是 Quantization，都是希望夠在簡化模型複雜度、提升運算速度並降低能源與時間消耗的同時，保持模型原來的預測準確度。
:::</p></blockquote><p><a href=https://youtu.be/qD6iD4TFsdQ rel=external target=_blank>What is transfer learning?</a></p><footer class=footline></footer></article></div></main></div><aside id=R-sidebar class=default-animation><div id=R-header-topbar class=default-animation></div><div id=R-header-wrapper class=default-animation><div id=R-header class=default-animation><a id=R-logo class=R-default href=/index.html><div class=logo-title>SBK Hugo Site</div></a></div><search><form action=/search/index.html method=get><div class="searchbox default-animation"><button class=search-detail type=submit title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
<label class=a11y-only for=R-search-by>Search</label>
<input data-search-input id=R-search-by name=search-by class=search-by type=search placeholder=Search...>
<button class=search-clear type=button data-search-clear title="Clear search"><i class="fas fa-times" title="Clear search"></i></button></div></form></search></div><div id=R-homelinks class="default-animation homelinks"><div class="R-menu-divider default-animation"><hr class=padding></div><div class="R-sidebarmenu R-shortcutmenu-homelinks"><ul class="space collapsible-menu"><li data-nav-id=/index.html><a class=padding href=/index.html><i class="fa-fw fas fa-home"></i> Home</a></li></ul></div><div class="R-menu-divider default-animation"><hr class=padding></div><div class="R-sidebarmenu R-shortcutmenu-headercontrols"><ul></ul></div><div class="R-menu-divider default-animation"><hr class=padding></div></div><div id=R-content-wrapper class=highlightable><div class="R-sidebarmenu R-shortcutmenu-main"><ul class="enlarge morespace collapsible-menu"><li data-nav-id=/books-notes/index.html><a class=padding href=/books-notes/index.html>Books Notes</a><ul id=R-subsections-0771445a148f63eb6cc1a9b7ad45a36a class=collapsible-menu></ul></li><li data-nav-id=/data-structure/index.html><a class=padding href=/data-structure/index.html>Data Structures</a><ul id=R-subsections-58892abc7cea06bf1839098c82b3eb4d class=collapsible-menu></ul></li><li data-nav-id=/job/index.html><a class=padding href=/job/index.html>Jobs</a><ul id=R-subsections-0fce2c1f4d6d23f49b605855a82f55aa class=collapsible-menu></ul></li><li data-nav-id=/knowledge/index.html><a class=padding href=/knowledge/index.html>Knowledges</a><ul id=R-subsections-0bdb754d722e03f187f2117c1ef8015d class=collapsible-menu></ul></li><li data-nav-id=/leetcode/index.html><a class=padding href=/leetcode/index.html>LeetCodes</a><ul id=R-subsections-76e85062179d09303530c47eb73fc667 class=collapsible-menu></ul></li><li data-nav-id=/problem-solutions/index.html><a class=padding href=/problem-solutions/index.html>Problem Solutions</a><ul id=R-subsections-4f9e0f3095337026c1723515d5409f89 class=collapsible-menu></ul></li><li data-nav-id=/security/index.html><a class=padding href=/security/index.html>Securities</a><ul id=R-subsections-66815ecaaecfc1c209e5637d03b258b2 class=collapsible-menu></ul></li><li data-nav-id=/side-project/index.html><a class=padding href=/side-project/index.html>Side Projects</a><ul id=R-subsections-3295de6e89859c4cf23a4292e734c881 class=collapsible-menu></ul></li><li class=parent data-nav-id=/survey-papers/index.html><a class=padding href=/survey-papers/index.html>Survey Papers</a><ul id=R-subsections-baa5a308e222e800d6e93248dad73a11 class=collapsible-menu><li data-nav-id=/survey-papers/android-+-security/a-mitm-based-penetration-test-efficiency-improvement-approach-for-traffic-encrypted-mobile-apps-of-power-industry/index.html><a class=padding href=/survey-papers/android-+-security/a-mitm-based-penetration-test-efficiency-improvement-approach-for-traffic-encrypted-mobile-apps-of-power-industry/index.html>A MITM Based Penetration Test Efficiency Improvement Approach for Traffic-Encrypted Mobile Apps of Power Industry</a></li><li data-nav-id=/survey-papers/android-+-security/a-mitmproxy-based-dynamic-vulnerability-detection-system-for-android-applications/index.html><a class=padding href=/survey-papers/android-+-security/a-mitmproxy-based-dynamic-vulnerability-detection-system-for-android-applications/index.html>A Mitmproxy-based Dynamic Vulnerability Detection System For Android Applications</a></li><li data-nav-id=/survey-papers/android-+-security/cross-site-scripting-attacks-on-android-hybrid-applications/index.html><a class=padding href=/survey-papers/android-+-security/cross-site-scripting-attacks-on-android-hybrid-applications/index.html>Cross-site Scripting Attacks on Android Hybrid Applications</a></li><li data-nav-id=/survey-papers/ml-dl-+-security/deepcase-semi-supervised-contextual-analysis-of-security-events---notes/index.html><a class=padding href=/survey-papers/ml-dl-+-security/deepcase-semi-supervised-contextual-analysis-of-security-events---notes/index.html>DEEPCASE Semi-Supervised Contextual Analysis of Security Events - Notes</a></li><li data-nav-id=/survey-papers/ml-dl-+-security/deeplog_-anomaly-detection-and-diagnosis-from-system-logs-through-deep-learning/index.html><a class=padding href=/survey-papers/ml-dl-+-security/deeplog_-anomaly-detection-and-diagnosis-from-system-logs-through-deep-learning/index.html>DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning</a></li><li data-nav-id=/survey-papers/federated-learning/eiffel_-ensuring-integrity-for-federated-learning---notes/index.html><a class=padding href=/survey-papers/federated-learning/eiffel_-ensuring-integrity-for-federated-learning---notes/index.html>EIFFeL: Ensuring Integrity For Federated Learning - Notes</a></li><li data-nav-id=/survey-papers/android-+-security/exploiting-ml-alg-for-efficient-detection-and-prevention-of-js-xss-attacks-in-android-based-hybrid-applications/index.html><a class=padding href=/survey-papers/android-+-security/exploiting-ml-alg-for-efficient-detection-and-prevention-of-js-xss-attacks-in-android-based-hybrid-applications/index.html>Exploiting ML ALG for Efficient Detection and Prevention of JS-XSS Attacks in Android Based Hybrid Applications</a></li><li data-nav-id=/survey-papers/android-+-security/gui-testing/fastbot_-a-multi-agent-model-based-test-generation-system/index.html><a class=padding href=/survey-papers/android-+-security/gui-testing/fastbot_-a-multi-agent-model-based-test-generation-system/index.html>Fastbot: A Multi-Agent Model-Based Test Generation System</a></li><li data-nav-id=/survey-papers/android-+-security/gui-testing/fastbot2_-reusable-automated-model-based-gui-testing-for-android-enhanced-by-reinforcement-learning/index.html><a class=padding href=/survey-papers/android-+-security/gui-testing/fastbot2_-reusable-automated-model-based-gui-testing-for-android-enhanced-by-reinforcement-learning/index.html>Fastbot2: Reusable Automated Model-based GUI Testing for Android Enhanced by Reinforcement Learning</a></li><li data-nav-id=/survey-papers/federated-learning/fedml-he---an-efficient-homomorphic-encryption-based-privacy-preserving-federated-learning-system---notes/index.html><a class=padding href=/survey-papers/federated-learning/fedml-he---an-efficient-homomorphic-encryption-based-privacy-preserving-federated-learning-system---notes/index.html>FedML-HE - An Efficient Homomorphic-Encryption-Based Privacy-Preserving Federated Learning System - Notes</a></li><li data-nav-id=/survey-papers/crypto/how-to-securely-collaborate-on-data_-decentralized-threshold-he-and-secure-key-update---notes/index.html><a class=padding href=/survey-papers/crypto/how-to-securely-collaborate-on-data_-decentralized-threshold-he-and-secure-key-update---notes/index.html>How to Securely Collaborate on Data: Decentralized Threshold HE and Secure Key Update - Notes</a></li><li data-nav-id=/survey-papers/android-+-security/identifying-vulnerabilities-of-ssl_tls-certificate-verification-in-android-apps-with-static-and-dynamic-analysis/index.html><a class=padding href=/survey-papers/android-+-security/identifying-vulnerabilities-of-ssl_tls-certificate-verification-in-android-apps-with-static-and-dynamic-analysis/index.html>Identifying vulnerabilities of SSL/TLS certificate verification in Android apps with static and dynamic analysis</a></li><li data-nav-id=/survey-papers/federated-learning/local-model-poisoning-attacks-to-byzantine-robust-federated-learning---notes/index.html><a class=padding href=/survey-papers/federated-learning/local-model-poisoning-attacks-to-byzantine-robust-federated-learning---notes/index.html>Local Model Poisoning Attacks to Byzantine-Robust Federated Learning - Notes</a></li><li data-nav-id=/survey-papers/android-+-security/tool/pentest-tools-survey/index.html><a class=padding href=/survey-papers/android-+-security/tool/pentest-tools-survey/index.html>Pentest Tools Survey</a></li><li data-nav-id=/survey-papers/digital-currency/the-state-of-ethereum-smart-contracts-security_-vulnerabilities-countermeasures-and-tool-support---notes/index.html><a class=padding href=/survey-papers/digital-currency/the-state-of-ethereum-smart-contracts-security_-vulnerabilities-countermeasures-and-tool-support---notes/index.html>The State of Ethereum Smart Contracts Security: Vulnerabilities, Countermeasures, and Tool Support - Notes</a></li><li data-nav-id=/survey-papers/android-+-security/uncovering-intent-based-leak-of-sensitive-data-in-android-framework/index.html><a class=padding href=/survey-papers/android-+-security/uncovering-intent-based-leak-of-sensitive-data-in-android-framework/index.html>Uncovering Intent based Leak of Sensitive Data in Android Framework</a></li><li class=active data-nav-id=/survey-papers/android-+-security/understanding-real-world-threats-to-deep-learning-models-in-android-apps/index.html><a class=padding href=/survey-papers/android-+-security/understanding-real-world-threats-to-deep-learning-models-in-android-apps/index.html>Understanding Real-world Threats to Deep Learning Models in Android Apps</a></li><li data-nav-id=/survey-papers/android-+-security/vaptai_-a-threat-model-for-vulnerability-assessment-and-pentesting-of-android-and-ios-mobile-banking-apps/index.html><a class=padding href=/survey-papers/android-+-security/vaptai_-a-threat-model-for-vulnerability-assessment-and-pentesting-of-android-and-ios-mobile-banking-apps/index.html>VAPTAi: A Threat Model for Vulnerability Assessment and Pentesting of Android and iOS Mobile Banking Apps</a></li><li data-nav-id=/survey-papers/android-+-security/wight_-wired-ghost-touch-attack-on-capacitive-touchscreens/index.html><a class=padding href=/survey-papers/android-+-security/wight_-wired-ghost-touch-attack-on-capacitive-touchscreens/index.html>WIGHT: Wired Ghost Touch Attack on Capacitive Touchscreens</a></li><li data-nav-id=/survey-papers/android-+-security/tool/%E6%9C%89%E9%97%9Cpentest%E4%BD%86%E8%B2%A2%E7%8D%BB%E5%BE%88%E7%88%9B%E7%9A%84%E4%B8%89%E7%AF%87%E8%AB%96%E6%96%87/index.html><a class=padding href=/survey-papers/android-+-security/tool/%E6%9C%89%E9%97%9Cpentest%E4%BD%86%E8%B2%A2%E7%8D%BB%E5%BE%88%E7%88%9B%E7%9A%84%E4%B8%89%E7%AF%87%E8%AB%96%E6%96%87/index.html>有關Pentest但貢獻很爛的三篇論文</a></li></ul></li><li data-nav-id=/terminology/index.html><a class=padding href=/terminology/index.html>Terminologies</a><ul id=R-subsections-a19bf87a9a9aaf0a4146b803a35492f8 class=collapsible-menu></ul></li><li data-nav-id=/toc/index.html><a class=padding href=/toc/index.html>TOCs</a><ul id=R-subsections-451d3779340ac1afa8683c0232808cbf class=collapsible-menu></ul></li><li data-nav-id=/tools/index.html><a class=padding href=/tools/index.html>Tools</a><ul id=R-subsections-bf1399820dde3dd110e03ace4147ff86 class=collapsible-menu></ul></li></ul></div><div class="R-sidebarmenu R-shortcutmenu-shortcuts"><ul class="space collapsible-menu"></ul></div><div id=R-footer-margin></div><div class="R-menu-divider default-animation"><hr class=padding></div><div class="R-sidebarmenu R-shortcutmenu-footercontrols"><ul></ul></div><div id=R-footer><p>Built with <a href=https://github.com/McShelby/hugo-theme-relearn title=love><i class="fas fa-heart"></i></a> by <a href=https://gohugo.io/>Hugo</a></p></div></div></aside><script src=/js/clipboard/clipboard.min.js?1743619851 defer></script><script src=/js/perfect-scrollbar/perfect-scrollbar.min.js?1743619851 defer></script><script src=/js/theme.min.js?1743619851 defer></script></body></html>